# PV

stateless한 애플리케이션 각 포드는 별도의 데이터를 가지고 있지 않으며, 단순히 요청에 대한 응답만을 반환한다.

stateful한 애플리케이션 포드 내부에서 특정 데이터를 보유하는 상태



포드의 데이터를 영속적으로 저장하기 위한 방법이 필요함.



도커에서는 단일 컨테이너의 디렉터리를 호스트와 공유함으로써 데이터를 보존한다.

```
docker run -v
```



상황 가정

쿠버네티스에서도 호스트의 디렉터리를 공유하여 데이터를 보존시키는 것이 가능하다.

하지만 쿠버네티스가 파드를 배치할때 임의의 노드에 배치하기 때문에 데이터가 각 노드에만 저장되고 파드가 적재되는 노드의 위치가 바뀌면 해당 데이터를 사용할 수 없게 되는 문제가 발생한다.



### Persistent Volume

 어느 노드에서도 접근해 사용할 수 있는 퍼시스턴트 볼륨을 사용할 수 있다.

퍼시스턴트 볼륨은 워커 노드들이 네트워크상에서 스토리지를 마운트해 영속적으로 데이터를 저장할 수 있는 볼륨을 의미한다.



파드에 장애가 생겨 다른 노드로 파드가 재배치 되더라도 해당 노드에서 퍼시스턴트 볼륨에 네트워크로 연결하여 데이터를 계속하여 사용할 수 있다.

네트워크로 연결해 사용할 수 있는 퍼시스턴트 볼륨의 예로는

1. NFS
2. EBS
3. Ceph
4. GlusterFS



기본적인 간단히 사용할 수 있는 볼륨의 종류

**로컬 볼륨**

1. hostPath : 호스트와 볼륨을 공유하기 위해서 사용
2. emptyDir : 포드의 컨테이너 간에 볼륨을 공유하기 위해 사용



**hostPath**

호스트의 디렉터리를 포드와 공유하여 데이터를 저장하는 방법.

```
apiversion: v1
kind: Pod
metadata:
 name: host-path-pod
spec:
 containers:
   - name: my-container
     image: busybox
     args:["tail","-f","/dev/null"]
     volumeMounts:
     - name: my-hostpath-volume
       mountPath: /etc/data
 volumes:
   - name: my-hostspath-volume
     hostPath:
       path: /tmp
```

volumes 항목에 볼륨을 정의한 뒤, 이를 포드를 정의하는 containers 항목에서 참조해 사용한다.

호스트의  /tmp를 포드의 /etc/data에 마운트함.



단점: 파드가 다른 노드로 옮겨질 시 기존 노드에 저장된 데이터를 사용할 수 없음



**emptyDir**

포드가 실행되는 도중에만 필요한 휘발성 데이터를 각 컨테이너가 함께 사용할 수 있도록 임시 저장 공간을 생성한다.

처음 생성 시 비어있는 형태로 생성되며 파드가 삭제되면 empryDir에 저장돼 있던 데이터도 함께 삭제된다.



emptyDir은 한 컨테이너가 파일을 관리하고 한 컨테이너가 그 파일을 사용하는 경우에 유용하게 사용할 수 있다.

```
apiversion: v1
kind: Pod
metadata:
 name: emptydir-pod
spec:
 containers:
   - name: content-creator
     image: busybox
     args:["tail","-f","/dev/null"]
     volumeMounts:
     - name: my-empryDir-volume
       mountPath: /data
       
   - name: apache-webserver
     image: httpd:2
     args:["tail","-f","/dev/null"]
     volumeMounts:
     - name: my-empryDir-volume
       mountPath: /usr/local/apache2/htdocs/
       
 volumes:
   - name: my-empryDir-volume
     hostPath:
       emptyDir:{}
```

컨테이너가 /data에 파일을 생성하면 해당 파일은 동시에 아파치 웹서버에 생성된다.



책 예시) 깃 허브 소스코드를 받아와 emptyDir 을 통해 애플리케이션 컨테이너에 공유해주는 사이드카 컨테이너

설정 파일을 동적으로 갱신하는 컨테이너를 파드에 포함



**네트워크 볼륨**

온프레미스 환경에서 구축 가능

1. NFS
2. isCSI
3. GlusterFS
4. Ceph

네트워크 볼륨위치는 특별히 정해진건 없음.

네트워크로 접근만 가능하면 됨 



NFS(Network File System)

대부분의 운영체제에서 사용할 수 있는 네트워크 스토리지로 여러 개의 클라이언트가 동시에 마운트해 사용할 수 있다는 특징이 있음

하나의 서버만으로 간편하게 사용할 수 있고, NFS를 마치 로컬 스토리지처럼 사용할 수 있다는 장점이 있음.

NFS 서버, NFS 클라이언트 가 필요하다.

NFS 서버는 영속적인 데이터가 실제로 저장되는 네트워크 스토리지 서버이다.

NFS 클라이언트는 NFS서버에 마운트해 스토리지에 파일을 읽고 쓰는 역할을 한다. NFS 클라이언트는 워커 노드의 기능을 사용것이므로 따로 준비할 필요는 없으며, NFS 서버만 별도 구축해주면 된다.



nfs-deployment.yaml

```
apiversion: v1
kind: Deployment
metadata:
 name: nfs-server
spec:
 selector:
  matchLablels:
   role: nfs-server
 template:
  metadata:
    labels:
      role: nfs-server
 spec:
  containers:
   - name: nfs-server
     image: gcr.io/google_containers/volume-nfs:0.8
     ports:
       - name: nfs
         containerPort: 2049
       - name: mountd
         containerPort: 20048
       - name: rpcbind
         containerPort: 111
     securityContext:
       privileged: true
```

nfs-service.yaml

```
apiversion: v1
kind: Service
metadata:
 name: nfs-service
spec:
 ports:
 - name: nfs
   port: 2049
 - name: nfs
   port: 20048
 - name: nfs
   port: 111
 selector:
   role: nfs-server
```



전부 완료했다면 NFS서버의 볼륨을 파드에서 마운트해 데이터를 영속적으로 저장한다.



 nfs-pod.yaml

```
apiversion: v1
kind: Pod
metadata:
 name: nfs-pod
spec:
 containers:
   - name: nfs-mount-container
     image: busybox
     args:["tail","-f","/dev/null"]
     volumeMounts:
     - name: nfs-volume
       mountPath: /mnt
             
 volumes:
   - name: nfs-volume
     nfs:
       path: /
       server: {NFS_SERVICE_IP}
```

컨테이너 내부에서 /mnt 디렉터리에 파일을 저장하면 실제로는 NFS 서버에 데이터가 저장된다.

volumes 항목에서 nfs 항목을 정의함으로써 NFS 서버의 볼륨을 사용한다고 명시함.

NFS의 볼륨의 마운트는 컨테이너 내부가 아닌 워커 노드에서 발생하므로 서비스의 DNS 이름으로 NFS 서버에 접근 불가능.



---



mongo-pvc.yaml

```
apiversion: v1
kind: PersistentVolumeClaim
metadata:
 name: mongodb-pvc # 클레임 사용 때 필요
spec:
 resources:
  requests:
   storage: 1Gi #요청하는 스토리지 양
 accessModes: #단일 클라이언트에 읽기쓰기 지원
   - ReadWriteOnce
 storageClassName: "" #동적 프로비저닝에서 사용
```



mongo-pv.yaml

```
apiversion: v1
kind: PersistentVolume
metadata:
 name: mongodb-pv
spec:
 resources:
  requests:
   storage: 1Gi #요청하는 스토리지 양
 accessModes: #단일 클라이언트에 읽기쓰기 지원 여러번 읽기만 가능
   - ReadWriteOnce
   - ReadOnlyMany
 persistentVolumeReclaimPolicy: Retain
 gcePersistentDisk: 
   pdName: mongodb
   fsType: ext4
```



Reclaming

- Retain(유지)

  - persistentvolumeclaim 삭제하면 persistentvolume 여전히 존재하고 볼륨은 해제된 것으로 간주

    연관된 스토리지 자산의 데이터를 수동으로 정리 (디스크 유지)

- Delete (삭제)

  - 외부 인프라의 연관된 스토리지 자산을 모두 제거 (디스크 파괴)

- Recycle(재사용)

  - rm -rf /thevolume/* 볼륨에 대한 기본 스크럽()을 수행하고 새 클리엠이ㅔ 대해 다시 사용할 수 있도록 함 (디스크 포맷)

인프라 세부사항을 알지 못해도 클러스터의 스토리지를 사용할 수 있도록 제공해주는 리소스

포드 안에 영구 볼륨을 사용하도록 하는 방법은 다소 복잡



---

실습단계 - pod pv pvc 생성

