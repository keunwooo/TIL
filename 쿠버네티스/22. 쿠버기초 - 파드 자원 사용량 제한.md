# 파드의 자원 사용량 제한

쿠버네티스 (컨테이너 오케스트레이션) 여러 대의 서버를 묶어 리소스 풀로 사용할 수 있음

클러스터의 CPU나 메모리 등의 자원이 부족하면 필요한 용량만큼 서버를 동적으로 추가해서 수평적 확장이 가능하다.



클러스터 내부에서 자원 활용률을 늘리는 것 또한 중요하다.

자원 활용률 - 서버 클러스터에서 자원을 얼마나 효율적으로, 빠짐없이 사용하고 있는지를 의미한다.

예를 들어 쿠버네티스에서 실행 중인 컨테이너의 CPU,메모리 사용률이 현저하게 낮거나, 유휴 상태의 컨테이너에 불필요하게 많은 자원을 할당하면 이는 컴퓨팅 자원의 활용률이 낮다고 말할 수 있음.



각 컨테이너의 자원 사용량을 제한하여 남는 자원을 어떻게 사용할 수 있을지에 대한 전략을 세워야한다.

---

## 컨테이너와 파드의 자원 사용량 제한



#### Limit

쿠버네티스는 기본적으로 도커를 컨테이너 런타임으로 사용하기 때문에 파드를 생성할 때 docker 와 동일한 원리로(cgroup) CPU,메모리의 최대 사용량을 제한할 수 있다. 

 자원 할당량을 설정하지 않으면 파드의 컨테이너가 노드의 물리자원을 모두 사용할 수 있기 때문에 노드의 자원이 모두 고갈되는 상황이 발생한다.



파드 자체에 자원 사용량을 명시적으로 설정하는 것으로 이를 예방한다.



Limits는 해당 파드의 컨테이너가 최대로 사용할 수 있는 자원의 상한선을 의미한다.

파드의 CPU,메모리 사용량 제한

```
apiVersion: v1
kind: Pod
metadata:
 name: resource-limit-pod
 labels:
  name: resource-limit-pod
spec:
 containers:
 - name: nginx
   image: nginx:latest
 resources:
  limits:
   memory: "256Mi"
   cpu: "1000m"
```

spec.containers.resources.limits 정의

memory: "256Mi" 

```
docker run --memory 256m
```

cpu: "1000m" cpu 1개를 의미한다. 

```
docker run --cpus 1
```



한 파드에 여러개의 컨테이너가 정의되어 있으면 각 컨테이너에 대해 자원을 각각 할당할 수 있다.



```
kubectl describe node 
```

명령어를 통해서 워커 노드의 가용자원을 간단하게 확인이 가능하다.



Non-terminated Pods 항목에서 실행 중인 파드들의 자원 할당량을 확인 가능.

Allocated resources 항목에서 실행 중인 파드들의 자원 할당량을 모두 더한 값이 출력



#### Request

Requests는 적어도 이 만큼의 자원은 컨테이너에게 보장돼야 한다는 것을 의미한다.

Requests는 쿠버네티스에서 자원의 오버커밋을 가능하게 만드는 기능이기 때문에 정확한 개념을 알고 넘어가는 것이 좋다.



```
...
 resources:
  limits:
   memory: "256Mi"
   cpu: "1000m"
...
```



오버커밋이란?

오버커밋은 한정된 컴퓨팅 자원을 효율적으로 사용하기 위한 방법으로, 사용할 수 있는 자원보다 더 많은 양을 가상 머신이나 컨테이너에게 할당함으로써 전체 자원의 사용률을 높이는 방법이다.



각 컨테이너가 사용을 보장받을 수 있는 경계선, 컨테이너가 최소한으로 보장받아야 하는 자원의 양

파드의 CPU,메모리 사용량 보장

```
apiVersion: v1
kind: Pod
metadata:
 name: resource-limit-with-request-pod
 labels:
  name: resource-limit-with-request-pod
spec:
 containers:
 - name: nginx
   image: nginx:latest
 resources:
  limits:
   memory: "256Mi"
   cpu: "1000m"
  requests:
   memory: "128Mi"
   cpu: "500m"
```



-> 최소한 128Mi의 메모리 사용은 보장되지만, 유후 메모리 자원이 있다면 최대 256Mi까지 사용할 수 있다.

-> 최소한 0.5 CPU 만큼 사용이 가능하지만, 유후 CPU 자원이 있다면 최대 1CPU까지 사용할 수 있다.



requests는 컨테이너가 보장받아야 하는 최소한의 자원을 뜻하기 때문에, 노드의 총 자원의 크기보다 더 많은 양의 requests를 할당할 수는 없다.

따라서 쿠버네티스의 스케줄러는 파드의 requests만큼 여유가 있는 노드를 선택해 파드를 생성한다.

즉, 파드를 할당할 때 사용되는 자원 할당 기준은 limit이 아닌 requests이다.



ex) 쿠버네티스 노드 (전체 메모리 1GB)



1. Limit:750MB , Request: 500MB (할당가능)

2. Limit:750MB , Request: 600MB (할당불가능)

   

할당된 메모리 Limit: 750MB (75% 사용 중), 할당된 메모리 Requests: 500MB(50% 사용 중)



노드에 할당된 파드의 Limits 값의 합은 노드의 물리자원 크기를 초과할 수 있음. Why? 오버 커밋을 위해서 Limits가 750MB인 두 개의 파드가 할당될 수도 있기 때문이다.



#### CPU 자원 사용량 제한 원리

쿠버네티스에서는 CPU를 m(밀리코어) 단위로 제한, 1개의 CPU = 1000m



```
 resources:
  limits:
   memory: "256Mi"
   cpu: "1000m"
  requests:
   memory: "128Mi"
   cpu: "500m"
```

 resources. limits.cpu: "1000m" 는 파드의 컨테이너가 최대 1개만큼의 CPU를 사용할 수 있다.

 resources. requests.cpu:"500m" CPU가 보장받아야 하는 최소한의 CPU 자원을 설정

```
docker run --cpu-shares
```

CPU의 Requests는 docker run의 --cpu-shares 옵션과 같음.



서버에 cpu가 실제로 몇개 있는지 상과없이 --cpu-shares의 할당 비율에 따라서 컨테이너가 사용할 수 있는 CPU 자원이 결정되는 옵션이다.



--cpu-shares 옵션은 --cpus(Limit)와 함께 사용하면 CPU 자원에 오버커밋을 적용하는 것이 가능하다.



ex) 컨테이너 A

Limit(--cpus):700m

Request(--cpu-shares):500m



1개의 CPU 중 최대 0.7개의 CPU 사용 가능 (70%)



컨테이너가 하나만 존재하는 상황이면 Request와 상관없이 CPU의 Limit 값만큼(700m) 사용이 가능하다.

하지만 두개의 컨테이너가 CPU 자원을 최대로 사용하는 상태라면?



```
컨테이너 A

Limit(--cpus):700m

Request(--cpu-shares):500m
```

```
컨테이너 B

Limit(--cpus):700m

Request(--cpu-shares):500m
```

Request 값이 500m으로 동일하기 때문에 CPU 자원이 포화 상태일 때는 각 컨테이너가 정확히 1:1의 비율로 CPU를 나눠서 사용한다.

Request 값인 500m는 최종적으로 각 컨테이너에 보장돼야 하는 최소한의 CPU 자원을 나타낸다.



이 상태에서는 전체 CPU 자원인 1000m 만큼의 Request를 모두 소진했기 때문에 새로운 Reuqest를 가지는 컨테이너를 새롭게 할당하는 것은 불가능하다.



**Request보다 더 많은 CPU 자원을 사용하려 할때**

자원의 경합이 발생하는 상황

다른 컨테이너가 CPU를 사용하고 있지 않아 유후 CPU 자원이 발새아하면 다른 컨테이너는 Limit에 설정된 CPU값만큼 사용할 수 있다.



p483

컨테이너 A가 Request 보다 더 많은 CPU를 사용중이다.

컨테이너 B가 Request만큼 CPU를 사용하려고 시도한다.

컨테이너 A에는 스로틀(Throttle)이 발생

컨테이너 B는 Request에 명시한 만큼의 CPU 비율을 사용할 수 있다.



Request보다 더 많은 CPU를 사용해 CPU 경합이 발생하더라도 컨테이너의 CPU 사용량을 스로틀을 통해 억제할 수 있다.



**Request에 할당되지 않은 여유 CPU 자원이 노드에 남아있는 경우**

Limit만큼의 CPU를 사용할 수 있는 상황이라면 컨테이너는 Limit까지 CPU 사용이 가능하다.



#### QoS 클래스와 메모리 자원 사용량 제한 원리

메모리는 CPU와 달리 압축 불가능한 자원으로 취급되기 때문에 메모리 사용량에 경합이 발생하면 문제가 심각해진다.

쿠버네티스에서는 이런 상황에서 가용메모리를 확보하기 위해 우선순위가 낮은 파드 또는 프로세스를 강제 종료하도록 설계되어 있다.

강제로 종료된 파드는 다른 노드로 옮겨가며 이를 Eviction이라 한다.



쿠버네티스는 파드의 컨테이너에 설정된 Limit과 Request 값에 따라 내부적으로 우선순위를 계산한다.

파드의 우선순위를 구별하기 위해 3가지 종류의 QoS (Quality of Service) 클래스를 명시적으로 파드에 설정한다.



```
kubectl describe nodes
```

를 통해서 Condition 값을 확인하여 각종 노드의 이상 상태 정보를 확인한다.



MemoryPressure, DiskPressure  등..

kubelet이 자원상태를 주기적으로 확인하면서 상태 값을 갱신한다.



MemoryPressure는 노드의 가용 메모리가 100Mi 이하일 때 발생하도록 kubelet에 설정되어 있음.

해당 노드에서 실행중이던 모든 파드에 대해 순위를 매기고 우선순위가 가장 낮은 파드를 다른 노드로 퇴거시킨다.

MemoryPressure 가 true인 노드에는 더이상 파드를 할당하지 않는다.



OOM( Out of Memory)

리눅스 시스템의 OOM Killer 기능을 통해 컨테이너 프로세스를 강제 종료해 메모리를 확보한다.

OOM 점수가 높을수록 강제로 종료될 가능성이 크다

docker 는 기본적으로 OOM이 -999이므로 종료될 가능성이 적다



```
ps aux | grep dockerd

ls /proc/<process number>

cat proc/<process number>/oom_score_adj
```



**QoS - Guranteed 클래스** 

파드의 Limit과 Request 값에 따라서 QoS 클래스 라는 것을 모든 파드에 대해서 설정한다.

QoS 클래스

1. BestEffort
2. Burstable
3. Guranteed

자동으로 설정된다.

```
kubectl describe pod ~~ | grep QoS
```

명령어로 QoS 클래스 확인



Guarnateed : 파드의 컨테이너에 설정된 Limit과 Request의 값이 완전히 동일할 때 부여되는 클래스이다.



```
resources:
  limits:
   memory: "256Mi"
   cpu: "1000m"
```

Reuqest 없이 Limit만 설정하면 Request값이 Limit과 동일하게 설정되기 때문에 Guranteed로 분류된다.

해당 클래스로 분류되는 파드는 Limit과 Request가 동일하기 때문에 할당받은 자원을 아무런 문제없이 사용이 가능하다.

오버커밋이 허용되지 않은 상태이다. 즉, 할당받은 자원의 사용을 안정적으로 보장(Guranteed) 받을 수 있다.



Guranteed 클래스의 파드내부에서 실행되는 프로세스들은 모두 기본 OOM 점수가 -998이다.



도커데몬이나 kubelet의 프로세스와 거의 동일한 레벨로 프로세스가 보호받기 떄문에 노드에서 메모리가 고갈되더라도 시스템 컴포넌트가 요구하지 않는 한 Guranteed 클래스의 파드나 프로세스가 강제로 종료되는 일은 없다.



**QoS - BestEffort 클래스** 

Request와 Limit을 아예 설정하지 않은 파드에 설정되는 클래스이다.

Limit 값을 설정하지 않았기 때문에 노드에 유휴자원이 있다면 제한없이 모든 자원을 사용할 수 있다.

Request 또한 설정되지 않았기 때문에 파드는 사용을 보장받을 수 있는 자원이 존재하지 않는다.

때에 따라서 노드의 모든 자원을 사용할 수 있지만 전혀 못할 수도 있음.



**QoS - Busrtable 클래스** 

Request와 Limit이 설정돼어 있고 Limit 값이 Request보다 큰 파드

Request에 지정된 자원만큼 사용이 보장되지만, 상황에 따라 Limit 까지 자원을 사용할 수 있음.

순간적으로 자원의 한계를 확장해 사용할 수 있는 파드



파드의 재시작 정책 (OOM killer에 의해 컨테이너 프로세스가 종료되어 재시작 될 시)

1. Guranteed
2. Bustable
3. BestEffort

우선순위는 바뀔수 있음 자원 사용량에 따라 우선순위 변경 (메모리 사용량)



자원 오버커밋 (생략)

ResourceQuota, LimitRanger

1. 네임스페이스에서 할당할 수 있는 자원의 총합 제한
2. 생성할수 있는 리소스 개수 제한



### 스케쥴링

kube-system에서 동작중

**kube-scheduler** (Pod)

API 서버의 Watch(kubelet이 걸어둠)를 통해 nodeName이 비어 있는 파드 데이터가 저장됐다는 사실을 전달 받음

즉 요청에 의해 파드의 데이터가 etcd에 저장되었지만 아직 노드에 스케줄링 되지 않은 파드를 감지한다.

nodeName이 없는 파드를 적절한 노드에  API 서버를 통해 바인딩을 요청하여 스케줄링한다.



노드 선택

1. 노드 필터링 : 파드 할당 노드 필터링
2. 노드 스코어링 : 가중치 부여



파드 할당

1. NodeSelector
2. Node Affinity
3. Pod Affinity



**YAML 파일에 노드의 이름을 직접 명시 하여 할당 가능**

```
kubectl get nodes
```

```
...
spec:
 nodeName: ip-10-43-09.30.....
```

이름을 알아야 가능해서 불편함.



**노드의 라벨을 통해 할당**

```
kubectl get nodes --show-labels
```



미리 설정된 라벨은 kubernetes.io/ 라는 접두어로 시작한다.



노드에 라벨추가

```
kubectl label nodes <name> mylabel/disk=ssd
```

```
kubectl label nodes <name> mylabel/disk=hhd
```



```
sepc:
 nodeSelector:
  mylabel/disk: hdd
```



만약 동일 라벨이 2개 이상이면 그 중 하나가 선택

파드 스케줄링 방법은 각 단일 파드에 대해서 수행됨! 디플로이먼트나 레플리카셋은 selector를 지정하더라도 하나씩 독립적으로 스케줄링 된다.



**Node Affinity**

nodeSelector에서 좀 더 확장된 라벨 선택 기능 제공

반드시 충족 조건, 선호하는 조건을 별도로 정의 가능



2가지 옵션

1. requiredDuringSchedulingIgnoredDuringExecution : 반드시 만족해야하는 제약조건

2. PreferredDuringSchedulingIgnoredDuringExecution : 선호하는 제약조건



```
spec:
 affinity:
  nodeAffinity:
   requiredDuringSchedulingIgnoredDuringExecution:
    nodeSelectorTerms:
    - matchExpressions:
      - key: mylabel/disk
        operator: In
        values:
        - ssd
        - hhd
 containers:
 - name:
   image:
```



```
    nodeSelectorTerms:
    - matchExpressions:
      - key: mylabel/disk
        operator: In
        values:
        - ssd
        - hhd
```

operator: In - key 라벨의 Values 값 ㅈ중 하날르 만족하는 노드에 파드를 스케줄링 한다. Notin, Exists, DoesNotExist, Gt, Lt



```
spec:
 affinity:
  nodeAffinity:
   PreferredDuringSchedulingIgnoredDuringExecution:
   - weight: 80
     preference:
      matchExpressions:
      - key: mylabel/disk
        operator: In
        values:
        - ssd
 containers:
 - name:
   image:
```

weight - 선호도를 나타내는 가중치 



**Pod Affinity**

