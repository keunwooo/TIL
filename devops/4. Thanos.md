# Thanos

초보자 사용법

https://hyunki1019.tistory.com/128?category=693849

tar.gz 압축 풀기 **tar -zxvf**



프로메테우스 다운로드

https://prometheus.io/download/



그라파나 다운로드

https://grafana.com/grafana/download



sudo service grafana-server start



타노스 다운로드

https://github.com/thanos-io/thanos/releases



타노스 튜토리얼

https://katacoda.com/thanos/courses/thanos/2-lts

---

튜토리얼 1번



1. 프로메테우스 yml 설정파일 작성

```
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: eu1
    replica: 0

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['127.0.0.1:9090']
  - job_name: 'sidecar'
    static_configs:
      - targets: ['127.0.0.1:19090']
```

2. 볼륨 연결 디렉토리 생성

```
mkdir -p prometheus0_eu1_data
```

3. 프로메테우스 배포

```
docker run -d --net=host --rm \
    -v $(pwd)/prometheus0_eu1.yml:/etc/prometheus/prometheus.yml \
    -v $(pwd)/prometheus0_eu1_data:/prometheus \
    -u root \
    --name prometheus-0-eu1 \
    quay.io/prometheus/prometheus:v2.14.0 \
    --config.file=/etc/prometheus/prometheus.yml \
    --storage.tsdb.path=/prometheus \
    --web.listen-address=:9090 \
    --web.external-url=https://2886795276-9090-cykoria03.environments.katacoda.com \
    --web.enable-lifecycle \ 
    --web.enable-admin-api && echo "Prometheus EU1 started!"
```



컨테이너 사망 원인..?이 뭐지

-> 도커로 안돌리고 wget으로 받아서 설치한다음 돌리고 있어서 내린 후 다시 컨테이너 실행

해봤더니 종료되지 않음



도커로 배포함.. 배포하고 접속되는지 확인( 나는 도커로 안하고 설치해서 사용 중..흠..)



4. 타노스 사이드카 설치



배포 한 각 Prometheus 인스턴스에 사이드카를 설치

> 이 설정에서 사이드카에 필요한 유일한 구성은 Prometheus API URL 및 구성 파일에 대한 액세스입니다. 이전 버전에서는 Prometheus 메트릭에 액세스 할 수 있고 후자는 사이드카가 런타임에 Prometheus 구성을 다시로드 할 수 있도록 허용합니다.



타노스 사이드카 도커 실행문 분석..

```
docker run -d --net=host --rm \
    -v $(pwd)/prometheus0_eu1.yml:/etc/prometheus/prometheus.yml \
    --name prometheus-0-sidecar-eu1 \
    -u root \
    quay.io/thanos/thanos:v0.18.0 \
    sidecar \
    --http-address 0.0.0.0:19090 \
    --grpc-address 0.0.0.0:19190 \
    --reloader.config-file /etc/prometheus/prometheus.yml \
    --prometheus.url http://127.0.0.1:9090 && echo "Started sidecar for Prometheus 0 EU1"
```



d, --detach=false: Detached 모드입니다. 보통 데몬 모드라고 부르며 컨테이너가 백그라운드로 실행됩니다.

-v, --volume=[]: 데이터 볼륨을 설정입니다. 호스트와 공유할 디렉터리를 설정하여 파일을 컨테이너에 저장하지 않고 호스트에 바로 저장합니다. 호스트 디렉터리 뒤에 **:ro**, **:rw**를 붙여서 읽기 쓰기 설정을 할 수 있으며 기본 값은 **:rw**입니다

--name=””: 컨테이너에 이름을 설정합니다.

-u, --user=””: 컨테이너가 실행될 리눅스 사용자 계정 이름 또는 UID를 설정합니다.

--net=”bridge”: 컨테이너의 네트워크 모드를 설정합니다.

- bridge: Docker 네트워크 브리지에 새 네트워크를 생성합니다.
- none: 네트워크를 사용하지 않습니다.
- container:<컨테이너 이름, ID>: 다른 컨테이너의 네트워크를 함께 사용합니다.
- host: 컨테이너 안에서 호스트의 네트워크를 그대로 사용합니다. 호스트 네트워크를 사용하면 D-Bus를 통하여 호스트의 모든 시스템 서비스에 접근할 수 있으므로 보안에 취약해집니다.



http://pyrasis.com/book/DockerForTheReallyImpatient/Chapter20/28 참고

5. 

타노스 쿼리 도커 실행문 분석..



6. 타노스 쿼리 배포

```
docker run -d --net=host --rm \
    --name querier \
    quay.io/thanos/thanos:v0.18.0 \
    query \
    --http-address 0.0.0.0:29090 \
    --query.replica-label replica \
    --store 127.0.0.1:19190 \
    --store 192.168.150.182:19191 && echo "Started Thanos Querier"
    
    
```

- 클러스터 접근 -> 노드포트로 해야할듯???
- 로드밸런서 부재 ....





외부레이블?조사



다중 클러스터 구성 후 엔드포인트 제공해서 되는지 확인..



1. yml 파일 작성

prometheus0_us1.yml

```
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: us1
    replica: 0

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['127.0.0.1:9091']
  - job_name: 'sidecar'
    static_configs:
      - targets: ['127.0.0.1:19091']
```



2. 볼륨 연결할 디렉토리 생성

```
mkdir -p prometheus0_us1_data
```



3. 프로메테우스 배포

```
docker run -d --net=host --rm \
    -v $(pwd)/prometheus0_us1.yml:/etc/prometheus/prometheus.yml \
    -v $(pwd)/prometheus0_us1_data:/prometheus \
    -u root \
    --name prometheus-0-us1 \
    quay.io/prometheus/prometheus:v2.14.0 \
    --config.file=/etc/prometheus/prometheus.yml \
    --storage.tsdb.path=/prometheus \
    --web.listen-address=:9091 \
    --web.external-url=https://2886795351-9091-ollie02.environments.katacoda.com \
    --web.enable-lifecycle \
    --web.enable-admin-api && echo "Prometheus 0 US1 started!"
```

9091오픈



4. 사이드카 추가하기

```
docker run -d --net=host --rm \
    -v $(pwd)/prometheus0_us1.yml:/etc/prometheus/prometheus.yml \
    --name prometheus-0-sidecar-us1 \
    -u root \
    quay.io/thanos/thanos:v0.18.0 \
    sidecar \
    --http-address 0.0.0.0:19091 \
    --grpc-address 0.0.0.0:19191 \
    --reloader.config-file /etc/prometheus/prometheus.yml \
    --prometheus.url http://127.0.0.1:9091 && echo "Started sidecar for Prometheus 0 US1"
```

5. 

이제 사이드카가 제대로 작동하는지 확인하기 위해 추가 된 사이드카를 포함하도록 Prometheus 스크랩 구성을 수정 해 보겠습니다.

항상 그렇듯이 각 구성에 대해 Copy To Editor를 클릭하여 구성을 각 파일에 전파하십시오.

사이드카 덕분에 모든 변경 사항이 Prometheus에서 즉시 다시로드되고 업데이트됩니다!

```
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: us1
    replica: 0

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['127.0.0.1:9091']
  - job_name: 'sidecar'
    static_configs:
      - targets: ['127.0.0.1:19091']
```



다음 튜토리얼 필요 ( 멀티 연결 구성 )



(sidecar, thanos 세부 옵션 규칙 공부 필요)



튜토리얼2번

1. 단일 클러스터 구성
2. Minio 구동 후 버킷 연동?
3. 타노스 Store Gateway









# Sidecar

Thanos는 Prometheus 서버와 동일한 머신 또는 동일한 포드에서 실행되는 Sidecar 프로세스를 통해 기존 Prometheus 서버와 통합됩니다.

Sidecar의 목적은 Prometheus 데이터를 Object Storage 버킷에 백업하고 다른 Thanos 구성 요소가 gRPC API를 통해 Prometheus 측정 항목에 액세스 할 수 있도록하는 것입니다.

사이드카는 다시로드 Prometheus 엔드 포인트를 사용합니다. --web.enable-lifecycle 플래그로 활성화되어 있는지 확인합니다.

The Sidecar makes use of the `reload` Prometheus endpoint. Make sure it’s enabled with the flag `--web.enable-lifecycle`.



#### External storage

다음은 구성된 개체 저장소에 Prometheus의 데이터를 쓰도록 사이드카를 구성합니다.

```
thanos sidecar \
    --tsdb.path            /var/prometheus \          # TSDB data directory of Prometheus
    --prometheus.url       "http://localhost:9090" \  # Be sure that the sidecar can use this url!
    --objstore.config-file bucket_config.yaml \       # Storage configuration for uploading data
```

YAML 파일의 형식은 선택한 공급자에 따라 다릅니다. Thanos가 지원하는 구성 및 최신 스토리지 유형 목록의 예는 여기에서 확인할 수 있습니다.

이 롤아웃은 실행중인 Prometheus 인스턴스에 거의 영향을주지 않습니다. Thanos의 다른 부분을 파악하면서 데이터를 백업하고 있는지 확인하는 것이 좋습니다.

데이터 백업에 관심이없는 경우 --objstore.config-file 플래그를 생략 할 수 있습니다.



#### Store API

Sidecar 구성 요소는 gRPC Store API를 구현하고 노출합니다. 사이드카 구현을 사용하면 Prometheus에 저장된 메트릭 데이터를 쿼리 할 수 있습니다.

이전 섹션에서 사이드카를 확장하여 Prometheus 서버에 연결하고 Store API를 노출 해 보겠습니다.

```
thanos sidecar \
    --tsdb.path                 /var/prometheus \
    --objstore.config-file      bucket_config.yaml \       # Bucket config file to send data to
    --prometheus.url            http://localhost:9090 \    # Location of the Prometheus HTTP server
    --http-address              0.0.0.0:19191 \            # HTTP endpoint for collecting metrics on the Sidecar
    --grpc-address              0.0.0.0:19090              # GRPC endpoint for StoreAPI
```



### Uploading old metrics.



#### External Labels

Prometheus는 주어진 Prometheus 인스턴스의 "외부 레이블"구성을 허용합니다. 이는 해당 인스턴스의 역할을 전역 적으로 식별하기위한 것입니다. Thanos는 모든 인스턴스에서 데이터를 집계하는 것을 목표로하므로 일관된 외부 레이블 세트를 제공하는 것이 중요합니다!

모든 Prometheus 인스턴스에는 전역 적으로 고유 한 식별 레이블 집합이 있어야합니다. 예를 들어 Prometheus의 구성 파일에서

```
global:
  external_labels:
    region: eu-west
    monitor: infrastructure
    replica: A
```



### [Querier/Query](https://thanos.io/tip/thanos/components/query.md) 

이제 하나 이상의 Prometheus 인스턴스에 대한 Sidecar를 설정 했으므로 Thanos의 전역 쿼리 계층을 사용하여 모든 인스턴스에 대해 PromQL 쿼리를 한 번에 평가하려고합니다.

쿼리 구성 요소는 상태 비 저장이고 수평 확장이 가능하며 여러 복제본으로 배포 할 수 있습니다. 사이드카에 연결되면 주어진 PromQL 쿼리를 위해 어떤 Prometheus 서버에 연결해야하는지 자동으로 감지합니다.

Thanos Querier는 또한 Prometheus의 공식 HTTP API를 구현하므로 Grafana와 같은 외부 도구와 함께 사용할 수 있습니다. 또한 임시 쿼리를위한 Prometheus UI의 파생물을 제공하고 상태를 저장합니다.

아래에서는 Sidecar에 연결하고 HTTP UI를 노출하기 위해 Thanos Querier를 설정합니다.



```
thanos query \
    --http-address 0.0.0.0:19192 \                                # HTTP Endpoint for Thanos Querier UI
    --store        1.2.3.4:19090 \                                # Static gRPC Store API Address for the query node to query
    --store        1.2.3.5:19090 \                                # Also repeatable
    --store        dnssrv+_grpc._tcp.thanos-store.monitoring.svc  # Supports DNS A & SRV records
```

Go to the configured HTTP address that should now show a UI similar to that of Prometheus. If the cluster formed correctly you can now query across all Prometheus instances within the cluster. You can also check the Stores page to check up on your stores.

이제 Prometheus와 유사한 UI를 표시해야하는 구성된 HTTP 주소로 이동합니다. 클러스터가 올바르게 형성되면 이제 클러스터 내의 모든 Prometheus 인스턴스를 쿼리 할 수 있습니다. 상점 페이지를 확인하여 상점을 확인할 수도 있습니다.





![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcKO0VF%2Fbtqz12KNbMV%2FaVJicQRckyKjGFnxd1vuCk%2Fimg.webp)

출처 https://www.metricfire.com/blog/ha-kubernetes-monitoring-using-prometheus-and-thanos/?GAID=1708236978.1613982132



## 쿠버네티스에서 실행시켜보자

헬름차트

출처 https://docs.bitnami.com/tutorials/create-multi-cluster-monitoring-dashboard-thanos-grafana-prometheus/



그대로 따라해보기

단, 로드밸런서 및 UI 단 접속은 노드포트로 바꿔서 접속해보자!



```
Step 1: Install the Prometheus Operator on each cluster

helm repo add bitnami https://charts.bitnami.com/bitnami

helm install prometheus-operator \
  --set prometheus.thanos.create=true \
  --set operator.service.type=ClusterIP \
  --set prometheus.service.type=ClusterIP \
  --set alertmanager.service.type=ClusterIP \
  --set prometheus.thanos.service.type=LoadBalancer \
  --set prometheus.externalLabels.cluster="data-producer-0" \
  bitnami/prometheus-operator
  
kubectl get svc | grep prometheus-operator-prometheus-thanos


Step 2: Install and configure Thanos

helm install thanos bitnami/thanos \
  --values values.yaml
  
Step 3: Install Grafana
      
helm install grafana bitnami/grafana \
  --set service.type=LoadBalancer \
  --set admin.password=GRAFANA-PASSWORD
  
  
```



해결해야 할 점

1.  Prometheus 설치 까진 Ok , But 네임스페이스변경을 하면 편할거 같음.

2.  Helm Chart 를 통해서 설치하는거 까지는 좋은데 Helm Chart를 커스텀마이징하는게 가능한지?
3. Helm Chart로 타노스쿼리를 올릴때 thanos-compactor, thanos-minio,ruler,storegateway 가 올라오지 않는 문제 해결해야함. (더불어 이 4개가 무슨 용도인지도)

4. 기존 쿠버네티스에 프로메테우스를 올리는 예제를 참고해서 거기에 사이드카를 추가해서 올리는 법을 찾아야함. (근본 방법)
5. 그냥 옵션줘서 사이드카를 한 포드에 생성하면 될거 같긴 한데 spec 조정을 어떻게 해야하는지?



kubectl edit svc thanos-query-frontend

helm install thanos bitnami/thanos --values values.yaml



```
helm repo add bitnami https://charts.bitnami.com/bitnami
helm install my-release bitnami/thanos
```



*values.yaml*

```
objstoreConfig: |-
  type: s3
  config:
    bucket: thanos
    endpoint: {{ include "thanos.minio.fullname" . }}.monitoring.svc.cluster.local:9000
    access_key: minio
    secret_key: KEY
    insecure: true
querier:
  stores:
    - SIDECAR-SERVICE-IP-ADDRESS-1:10901
    - SIDECAR-SERVICE-IP-ADDRESS-2:10901
bucketweb:
  enabled: true
compactor:
  enabled: true
storegateway:
  enabled: true
ruler:
  enabled: true
  alertmanagers:
    - http://prometheus-operator-alertmanager.monitoring.svc.cluster.local:9093
  config: |-
    groups:
      - name: "metamonitoring"
        rules:
          - alert: "PrometheusDown"
            expr: absent(up{prometheus="monitoring/prometheus-operator"})
minio:
  enabled: true
  accessKey:
    password: "minio"
  secretKey:
    password: "KEY"
  defaultBuckets: "thanos"
```



현재 

*values.yaml*

```
querier:
  stores:
          #- 10.111.16.122:10901
    - 192.168.150.182:30671
    - 10.111.16.122:10901
```



타노스 비트나미 헬름차트

https://github.com/bitnami/charts/tree/master/bitnami/thanos/#installing-the-chart

헬름차트 설치할때 values.yaml 을 같이 넣어주면 해당 옵션으로 생성됨.



Grafana를 비트나미 헬름차트로 생성 시 

PVC 에러



```
kubectl exec prometheus-prometheus-operator-prometheus-0 -c prometheus -- cat /etc/prometheus/prometheus.yml
```



# Thanos Http Api

앞서 언급했듯이 Thanos에서 제공하는 Query API는 Prometheus 2.x와 호환됩니다. API. 그러나 Prometheus에 추가 된 Thanos 기능에 대해 Thanos는 다음을 추가합니다.

- 부분 응답 동작ㅗ
- 아래 나열된 몇 가지 추가 매개 변수
- 사용자 지정 응답 필드.



Prometheus의 모든 Api 호출이 작동하는건 아닌듯...

(Prometheus의 Api 종류)

## Expression queries

### Instant queries

### Range queries

## Querying metadata

### Finding series by label matchers

### Getting label names

### Querying label values

## Expression query result formats

### Range vectors

### Instant vectors

### Scalars

### Strings

## Targets

## Rules

## Alerts

## Querying target metadata

## Querying metric metadata

## Alertmanagers

## Status

### Config

### Flags

### Runtime Information

### Build Information

### TSDB Stats

## TSDB Admin APIs

### Snapshot

### Delete Series

### Clean Tombstones



---

### 기본 Query

```
http://192.168.150.179:31137/api/v1 ...
```



```
kubectl get svc 

thanos-query 서비스를 NodePort로 변경후 매핑된 노드포트 번호로 쿼리 날리기
```



## Expression queries

### Instant queries

```
GET /api/v1/query
POST /api/v1/query

192.168.150.179:31163/api/v1/query?query=up&time=2021-02-24T20:10:51Z
192.168.150.115:30562/api/v1/query?query=up
```

### Range queries

```
GET /api/v1/query_range
POST /api/v1/query_range

192.168.150.179:31163/api/v1/query_range?query=up&start=2021-02-24T20:10:30Z&end=2021-02-25T20:11:00Z&step=1h
```



## Querying metadata

### Finding series by label matchers

```
GET /api/v1/series
POST /api/v1/series

192.168.150.179:31163/api/v1/series? --data-urlencode 'match[]=up' --data-urlencode 'match[]=process_start_time_seconds{job="prometheus"}'

사용용도 및 방법 잘 모르겠음 Series....
```



### Getting label names OK

```
GET /api/v1/labels
POST /api/v1/labels

http://192.168.150.179:31137/api/v1/labels

```



### Querying label values OK

```
GET /api/v1/label/<label_name>/values

http://192.168.150.179:31137/api/v1/label/job/values
```



## Expression query result formats

### Range vectors

### Instant vectors

### Scalars

### Strings

( 용도 및 사용법 잘 모르겠음)



## Targets

```
GET /api/v1/targets

192.168.150.179:31163/api/v1/targets

192.168.150.179:31163/api/v1/targets?state=active
```



## Rules

```
GET /api/v1/rules

192.168.150.179:31163/api/v1/rules
```



## Alerts

```
GET /api/v1/alerts

192.168.150.179:31163/api/v1/alerts
```



## Querying target metadata

```
GET /api/v1/targets/metadata

192.168.150.179:31163/api/v1/targets/metadata

(잘 모르겠음)
curl -G http://localhost:9091/api/v1/targets/metadata \
    --data-urlencode 'metric=go_goroutines' \
    --data-urlencode 'match_target={job="prometheus"}' \
    --data-urlencode 'limit=2'
    
```



## Querying metric metadata

```
GET /api/v1/metadata

192.168.150.179:31163/api/v1/metadata

192.168.150.179:31163/api/v1/metadata?metric=http_requests_total
```



## Alertmanagers

```
GET /api/v1/alertmanagers

192.168.150.179:31163/api/v1/alertmanagers
```



## Status

### Config

```
GET /api/v1/status/config

192.168.150.179:31163/api/v1/status/config
```

### Flags

```
GET /api/v1/status/flags

192.168.150.179:31163/api/v1/status/flags
```

### Runtime Information

```
GET /api/v1/status/runtimeinfo

192.168.150.179:31163/api/v1/status/runtimeinfo
```



### Build Information

```
GET /api/v1/status/buildinfo

192.168.150.179:31163/api/v1/status/buildinfo
```

### TSDB Stats

```
GET /api/v1/status/tsdb

192.168.150.179:31163/api/v1/status/tsdb
```



## TSDB Admin APIs

### Snapshot

```
POST /api/v1/admin/tsdb/snapshot
PUT /api/v1/admin/tsdb/snapshot

(잘 모르겠음)
```

### Delete Series

```
POST /api/v1/admin/tsdb/delete_series
PUT /api/v1/admin/tsdb/delete_series
```

### Clean Tombstones

```
POST /api/v1/admin/tsdb/clean_tombstones
PUT /api/v1/admin/tsdb/clean_tombstones
```



# Grafana로 쿼리 받기 

![image-20210302122318218](C:\Users\INNOGRID\AppData\Roaming\Typora\typora-user-images\image-20210302122318218.png)



![image-20210302122339526](C:\Users\INNOGRID\AppData\Roaming\Typora\typora-user-images\image-20210302122339526.png)



Query inspector 클릭

![image-20210302122411276](C:\Users\INNOGRID\AppData\Roaming\Typora\typora-user-images\image-20210302122411276.png)

```
192.168.150.179:30004/api/datasources/proxy/1/api/v1/query_range?query=node_scrape_collector_duration_seconds&start=1614653670&end=1614653970&step=15
```

(그라파나 포트번호)

그라파나 설치는 프로메테우스 자료 참고



helm install grafana bitnami/grafana --values values.yaml



chmod +x test.sh

추가된 Service 작동여부 확인



---



Istio - 프로메테우스 -> 타노스

<IPMI 보류>

