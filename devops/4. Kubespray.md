# KubeSpray

https://github.com/kubernetes-sigs/kubespray/blob/master/docs/roadmap.md

```
sudo apt install python3-pip -y 
sudo pip3 install --upgrade pip 
git clone https://github.com/kubernetes-sigs/kubespray.git 
cd kubespray 
sudo pip install -r requirements.txt 

cp -rfp inventory/sample inventory/mycluster 

# host 등록 방법 둘중 하나 선택 1) 자동생성 2) 직접 작성
1) declare -a IPS=(192.168.10.121 192.168.10.122 192.168.10.123) 
CONFIG_FILE=inventory/mycluster/hosts.yml python3 contrib/inventory_builder/inventory.py ${IPS[@]} 
vi inventory/mycluster/hosts.yml 

2) vi inventory/mycluster/inventory.ini

```



기본템플릿 복사 후 사용

```
ls inventory/mycluster
group_vars inventory.ini
```

- group_vars 디렉터리 안에는 클러스터 설치에 필요한 내용이 존재
- inventory.ini 파일에는 설치 대상 서버들이 정보를 설정



tree 구조 확인

```
sudo apt install tree
tree inventory/mycluster/group_vars
```



- inventory/mycluster/group_vars/all 디렉터리에는 설치 환경 및 방법에 관한 설정이 존재
  - all.yml : kubespray의 설치 및 설정 
  - azure.yml: 애저 환경에 설치할 때 적용할 설정
  - coreos.yml: 코어 OS 환경에 설치할때 적용할 설정
  - oci.yml: 오라클 클라우드 환경에 설치할 때 적용할 설정
  - docker.yml: 도커를 설치할 때 적용할 설정
  - openstack.yml: 오픈스택 환경에 설치할 때 적용할 설정



- inventory/mycluster/group_vars/etcd.yml 파일은 etcd 설치에 필요한 상세 설정 내용을 넣는다.
- inventory/mycluster/group_vars/k8s-cluster 디렉터리에는 쿠버네티스 관련 설정이 있음
  - k8s-cluster.yml: 쿠버네티스 클러스터를 설치할 때 적용할 설정 (버전 수정 등)
  - addons.yml: 쿠버네티스 클러스터를 설치한 후 추가로 설치할 구성 요소 관련 설정 (helm 등)
  - k8s-net-*.yml: 쿠버네티스 네트워크 플러그인별 상세 설정. 네트워크 플러그인은 k8s-cluster.yml 파일이 kube_network_plugin 변수에 설정한 내용을 적용하고, 상세 설정은 k8s-net-*.yml 파일의 설정을 따름



온프레스미스 환경에서 주의할점

- all.yml
  - http_proxy, https_proxy, no_proxy 확인
  - 인터넷에 직접 접근 할 수 없는 온프레미스 환경에서 http_proxy, https_proxy, no_proxy 필드에 프록시 설정
  - no_proxy 필드에는 프록시를 거치지 않을 내부 도메인 등을 명시
- k8s-cluster.yml
  - kube_service_addresses, kube_pods_subnet 확인
  - kube_service_addresses 필드에는 쿠버네티스의 서비스IP로 할당할 대역을 설정
  - kube_pods_subnet 필드에는 쿠버네티스 클러스터에 생성되는 파드들이 할당받을 IP 대역 설정
  - 두가 필드 대역이 이미 온프레미스 환경에서 사용 중인 대역이라면 변경해야함



inventory.ini 파일 구성

- [all]
  - 클러스터로 구성될 서버들의 호스트네임과 IP를 설정 (ansible에선 default로 /etc/ansible/hosts 적용 -i 옵션으로 인벤토리 지정 가능)
- [kube-master]
  - 마스터 노드로 사용할 서버의 호스트네임 설정 [all]에서 이미 정보를 설정했다면 호스트네임만 입력 가능
- [etcd]
  - 쿠버네티스의 클러스터 데이터를 저장하는 etcd를 설치할 노드의 호스트네임을 설정한다.
  - etcd와 마스터 노드를 별도로 구성하는것도 가능하지만 마스터 노드와 etcd를 같은 노드로 설정이 가능
- [kube-node]
  - 워커 노드로 사용할 서버의 호스트네임을 설정
- [k8s-cluster:children]
  - 쿠버네티스를 설치할 노드들을 설정 etcd가 설치될 노드를 제외하는 것이므로 보통 기본 설정 그대로 사용.



---



```
ansible-playbook -i inventory/mycluster/inventory.ini -v --become --become-user=root cluster.yml
```

```
ansible-playbook -i kubespray/inventory/mycluster/inventory.ini test.yaml
```

```
ansible-playbook -i inventory/mycluster/inventory.ini reset.yml
```

```
ansible-playbook -i inventory/[inventory.ini_path] scale.yml -v

ansible-playbook -i inventory/mycluster/inventory.ini scale.yml -v
```

```
ansible-playbook -i inventory/[inventory.ini_path] remove-node.yml --extra-vars "node=[nodeName]"

ansible-playbook -i inventory/mycluster/inventory.ini remove-node.yml --extra-vars node=node6
```

```
ansible -m ping all -i inventory/mycluster/inventory.ini
```

```
ansible-playbook -i inventory/mycluster/inventory.ini test.yml
```



test.yml

```
- hosts: all #inventory에서 정의한 그룹 대상
  become_user: yes

  tasks:
  - name: Test 1
    shell: git clone https://gist.github.com/e6dc474bf88b65468e6a019279314583.git

```



inventory/mycluster/inventory.ini

```
# ## Configure 'ip' variable to bind kubernetes services on a
# ## different ip than the default iface
# ## We should set etcd_member_name for etcd cluster. The node that is not a etcd member do not need to set the value, or can set the empty string value.
[all]
 node1 ansible_host=10.2.0.139  # ip=10.3.0.1 etcd_member_name=etcd1
 node2 ansible_host=10.2.0.174  # ip=10.3.0.2 etcd_member_name=etcd2
 node3 ansible_host=10.2.0.244  # ip=10.3.0.3 etcd_member_name=etcd3
 node4 ansible_host=10.2.0.31  # ip=10.3.0.4 etcd_member_name=etcd4
 node5 ansible_host=10.2.0.96  # ip=10.3.0.5 etcd_member_name=etcd5
 node6 ansible_host=10.2.0.158  # ip=10.3.0.6 etcd_member_name=etcd6

# ## configure a bastion host if your nodes are not directly reachable
# [bastion]
# bastion ansible_host=x.x.x.x ansible_user=some_user

[master]
 node1
 node2
 node3

[kube_control_plane]
 node1
# node2
# node3

[etcd]
 node1
# node2
# node3

[kube-node]
# node2
# node3
 node4
# node5
# node6

[calico-rr]

[k8s-cluster:children]
kube_control_plane
kube-node
calico-rr
```





---



kubespray 고가용성 구성은 nginx 리버스 프록시를 사용